{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/Murcha1990/ML_AI25/blob/main/Hometasks/Base/AI_HW3_Classification_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Домашнее задание 3. Линейная классификация (base)**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Оценивание и штрафы**\n",
    "\n",
    "С наступающим новым годом, друзья! Магистратура бежит быстро и мы бежим очень быстро, а зима — то время, когда хотелось бы бежать чуть медленнее. Поэтому это домашнее задание мы сделали сильно короче от его начальной версии!\n",
    "\n",
    "Как всегда, каждая из задач имеет «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "В задании две части:\n",
    "\n",
    "- Часть 1: написание логистической регрессии своими руками — уверенны, логлосс вы уже знаете как свои пять пальцев.\n",
    "- Часть 2: решение задачи классификации на текстах."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#from google.colab import drive # Если вы работаете в коллабе\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Часть 1. Логистическая регрессия своими руками (5 баллов)**\n",
    "\n",
    "Логистическая регрессия — безумно важная и удобная модель для понимания начальных концепций. Вы много практиковались с выведением формулы градиента логлосса, шага спуска, а в прошлом дз сделали SGD. Давайте сделаем ещё шаг вперед — и реализуем логистическую регрессию своими руками.\n",
    "\n",
    "На практике, часто хватает алгоритмов из коробки. Но иногда очень удобно сделать свой алгоритм."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Теоретическая сноска: почему LogLoss'а так много**\n",
    "\n",
    "Почти наверное (в математике это значит, во всех случаях, кроме множества размером 0) логлосс набил оскомину за несколько заданий. Давайте посмотрим на него ещё раз:\n",
    "\n",
    "В логистической регрессии функция потерь\n",
    "\n",
    "$$\\text{LogLoss}(y, \\hat{p}) = -\\left(y\\log \\hat{p} + (1-y)\\log (1-\\hat{p})\\right)$$\n",
    "\n",
    "Зачем мы так долго с ней возимся?\n",
    "\n",
    "#### **Пункт 1.**\n",
    "Во-первых, это **следствие максимизации правдоподобия** при биномиальной модели.\n",
    "\n",
    "Если считать, что целевая переменная (Y\\in{0,1}) распределена как\n",
    "\n",
    "$$P(Y=1 \\mid x) = \\hat{p}(x), \\qquad P(Y=0\\mid x) = 1-\\hat{p}(x),$$\n",
    "то правдоподобие выборки ( (x_i, y_i) )\\ равно\n",
    "$$L = \\prod_{i=1}^n \\hat{p}_i^{y_i}(1-\\hat{p}_i)^{1-y_i}.$$\n",
    "\n",
    "Максимизация $\\log L$ эквивалентна минимизации LogLoss.\n",
    "Таким образом, LogLoss — **единственная функция потерь, полностью согласованная с вероятностной моделью логистической регрессии**.\n",
    "\n",
    "#### **Пункт 2.**\n",
    "\n",
    "Во-вторых, логлосс поможет нам в будущем понять другие функции потерь. Так, например LogLoss является частным случаем **кросс-энтропии между истинным распределением и предсказанным**.\n",
    "\n",
    "Для двух распределений $p$ (истинного) и $q$ (предсказанного) кросс-энтропия определяется как\n",
    "\n",
    "$$H(p,q) = -\\sum_{k} p(k)\\log q(k).$$\n",
    "\n",
    "В бинарном случае истинное распределение дискретно:\n",
    "\n",
    "$$p = (y, 1-y), \\qquad q = (\\hat{p}, 1-\\hat{p}),$$\n",
    "и подстановка даёт\n",
    "\n",
    "$$H(p,q) = -\\left[y\\log \\hat{p} + (1-y)\\log (1-\\hat{p})\\right] = \\text{LogLoss}.$$\n",
    "\n",
    "\n",
    "В общем, любим, жалуем и реализуем.\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 1. Реализуйте класс логистической регрессии, обучаемой с помощью:**\n",
    "\n",
    "**Задание 1.1 (1.5 балла). Градиентного спуска**\n",
    "\n",
    "**Задание 1.2 (1.5 балла). Стохастического градиентного спуска**\n",
    "\n",
    "До этого вы писали код без ограничений. Здесь же необходимо соблюдать следующие условия:\n",
    "\n",
    "- Градиентный спуск необходимо записать в векторном виде;\n",
    "- Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
    "\n",
    "**Класс градиентного спуска должен:**\n",
    "- В качестве критерия останова использовать (одновременно):\n",
    "  - проверку на евклидову норму разности весов на двух соседних итерациях задаваемого параметром `tolerance`;\n",
    "  - достижение максимального числа итераций, задаваемого параметром `max_iter`.\n",
    "- Обладать атрибутом `loss_history`. В нём после вызова метода fit должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту). Данный атрибут необходим, чтобы проследить, что оптимизационный процесс действительно сходится;\n",
    "- Инициализировать веса случайным образом или нулевым вектором (на ваш выбор)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Полезно [почитать](https://scikit-learn.org/stable/developers/develop.html)."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Шаблон класса описан ниже, вам нужно реализовать каждую из заготовленных функций.**\n",
    "\n",
    "**ВАЖНО!** Мы заполняем данный шаблон, даже если он нам не нравится. Менять структуру класса и писать по-своему запрещено - за это будут сняты баллы."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LogReg(BaseEstimator):\n",
    "    def __init__(self, gd_type='stochastic',\n",
    "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'stochastic'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) — init weights\n",
    "        eta: learning rate\n",
    "        \"\"\"\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        ell, d = X.shape\n",
    "\n",
    "        # Инициализация весов\n",
    "        if self.w0 is not None:\n",
    "            self.w = self.w0.copy()\n",
    "        else:\n",
    "            self.w = np.zeros(d)\n",
    "\n",
    "        self.loss_history = []\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Записываем loss до обновления весов\n",
    "            self.loss_history.append(self.calc_loss(X, y))\n",
    "\n",
    "            # Вычисляем градиент\n",
    "            if self.gd_type == 'full':\n",
    "                grad = self.calc_gradient(X, y)\n",
    "            else:  # стохастический градиент\n",
    "                idx = np.random.randint(0, ell)\n",
    "                grad = self.calc_gradient(X[idx:idx+1], y[idx:idx+1])\n",
    "\n",
    "            # Обновляем веса\n",
    "            w_new = self.w - self.eta * grad\n",
    "\n",
    "            # Проверка критерия останова по норме разности весов\n",
    "            if np.linalg.norm(w_new - self.w) < self.tolerance:\n",
    "                self.w = w_new\n",
    "                break\n",
    "            self.w = w_new\n",
    "\n",
    "        return self\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        return self.sigmoid(X @ self.w)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
    "\n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        # Градиент LogLoss в векторном виде: (1/ell) * X^T * (sigmoid(Xw) - y)\n",
    "        ell = X.shape[0]\n",
    "        p = self.sigmoid(X @ self.w)\n",
    "        grad = (X.T @ (p - y)) / ell\n",
    "        return grad\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: float\n",
    "        \"\"\"\n",
    "        eps = 1e-15\n",
    "        p = self.sigmoid(X @ self.w)\n",
    "        loss = -np.mean(y * np.log(p + eps) + (1 - y) * np.log(1 - p + eps))\n",
    "        return loss"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь проверим работу вашего класса на синтетических данных."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100000, n_features=20, n_informative=2,\n",
    "    random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 2 (0.6 балла)**\n",
    "\n",
    "Теперь давайте тестировать модель.\n",
    "1. Обучите свою логистическую регрессию на синтетических данных (0.2 балла) — на полном GD и SGD;\n",
    "2. Cравните результат с моделью из библиотеки. Посчитайте roc-auc, accuracy, постройте ROC и PR кривые. , оцените разницу в производительности моделей по метрикам качества. Ответьте на вопросы:\n",
    "- Какая показывает лучший результат? Почему?\n",
    "- Есть ли что-то в модели из коробки, что по умолчанию делает её не равной вашей модели? Для ответа на этот вопрос вам может пригодитться [документация](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Её мы изучаем всегда, чтобы понимать тонкости реализации какого-либо метода в библиотеке. (0.4 балла)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr_sgd = LogReg(gd_type='stochastic')\n",
    "lr_sgd.fit(X_train, y_train)\n",
    "\n",
    "lr_full = LogReg(gd_type='full')\n",
    "lr_full.fit(X_train, y_train)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Обучаем логистическую регрессию на синтетических данных\n",
    "lr_sklearn = LogisticRegression(max_iter=1000)\n",
    "lr_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания\n",
    "models = {\n",
    "    'SGD (custom)': lr_sgd,\n",
    "    'Full GD (custom)': lr_full,\n",
    "    'sklearn LogReg': lr_sklearn,\n",
    "}\n",
    "\n",
    "# Считаем метрики\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Модель':<20} {'Accuracy':<12} {'ROC-AUC':<12}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    # sklearn возвращает 2D массив для predict_proba\n",
    "    if y_proba.ndim == 2:\n",
    "        y_proba = y_proba[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"{name:<20} {acc:<12.4f} {roc:<12.4f}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Построение ROC и PR кривых\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC curves\n",
    "ax1 = axes[0]\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    if y_proba.ndim == 2:\n",
    "        y_proba = y_proba[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax1.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True)\n",
    "\n",
    "# PR curves\n",
    "ax2 = axes[1]\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    if y_proba.ndim == 2:\n",
    "        y_proba = y_proba[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax2.plot(recall, precision, label=f'{name} (AUC = {pr_auc:.4f})')\n",
    "\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curve')\n",
    "ax2.legend(loc='lower left')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Визуализация сходимости loss\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(lr_sgd.loss_history)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('SGD Loss History')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(lr_full.loss_history)\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Full GD Loss History')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ответы на вопросы:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Какая модель показывает лучший результат? Почему?\n",
    "\n",
    "По метрикам качества (Accuracy, ROC-AUC, PR-AUC) все три модели показывают очень близкие результаты.\n",
    "Модель из библиотеки sklearn демонстрирует чуть более стабильное и иногда немного лучшее качество, однако различия не являются принципиальными.\n",
    "\n",
    "Это объясняется тем, что логистическая регрессия с L2-регуляризацией — выпуклая задача, и при корректной настройке оптимизации как Full GD, так и SGD сходятся к близкому минимуму.\n",
    "При этом sklearn LogisticRegression по умолчанию использует оптимизатор L-BFGS — квази-Ньютоновский метод, учитывающий информацию о кривизне функции потерь, что обеспечивает более быструю и устойчивую сходимость по сравнению с обычным GD и особенно с SGD.\n",
    "\n",
    "Full GD сходится стабильно, но медленно, так как использует весь датасет на каждой итерации.\n",
    "SGD обновляет веса по мини-батчам, из-за чего траектория оптимизации зашумлена и итоговое качество сильнее зависит от выбора learning rate.\n",
    "\n",
    "2. Что делает sklearn модель не равной нашей?\n",
    "\n",
    "Модель sklearn LogisticRegression не эквивалентна нашей,потому что по умолчанию включает ряд важных деталей:\n",
    "\n",
    "- Регуляризация:\n",
    "В sklearn по умолчанию используется L2-регуляризация (penalty='l2', C=1.0), тогда как в реализованной модели минимизируется чистый logloss без регуляризации.\n",
    "- Интерцепт (bias):\n",
    "В sklearn интерцепт добавляется автоматически (fit_intercept=True), а у нас свободный член отсутствует.\n",
    "- Оптимизатор:\n",
    "В sklearn по умолчанию применяется solver L-BFGS — квази-Ньютоновский метод, использующий информацию о кривизне функции потерь.\n",
    "У нас реализованы только методы Full Gradient Descent и Stochastic Gradient Descent (по одному объекту).\n",
    "- Критерии остановки:\n",
    "В обеих реализациях присутствует ограничение по max_iter, однако критерий ранней остановки различается:\n",
    "у нас  — по норме изменения весов ||w_new - w|| < tolerance,\n",
    "в sklearn — по параметру tol, определяемому внутренними условиями сходимости выбранного solver’а.\n",
    "-Стохастичность и воспроизводимость:\n",
    "В реализации SGD используется случайный выбор объекта без фиксированного random_state, что может приводить к вариативности результата, тогда как в sklearn поведение можно контролировать через random_state (для соответствующих solver’ов).\n",
    "\"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 3 (0.4 балла)**\n",
    "\n",
    "Для трех полученных моделей, визуализируйте прогнозы по данным на тестовой выборке. Для этого:\n",
    "- получите прогнозы;\n",
    "- сомжите данные, используя PCA. Не забудьте, что PCA полагает нулевое среднее и единичную дисперсию;\n",
    "- покрасьте данные по прогнозам.\n",
    "\n",
    "Как различаются графики для трёх моделей? И различаются ли?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Применяем PCA для визуализации (данные уже стандартизированы)\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "# Получаем прогнозы от всех моделей\n",
    "predictions = {\n",
    "    'SGD (custom)': lr_sgd.predict(X_test),\n",
    "    'Full GD (custom)': lr_full.predict(X_test),\n",
    "    'sklearn LogReg': lr_sklearn.predict(X_test)\n",
    "}\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, (name, y_pred) in zip(axes, predictions.items()):\n",
    "    scatter = ax.scatter(X_test_pca[:, 0], X_test_pca[:, 1],\n",
    "                         c=y_pred, cmap='coolwarm', alpha=0.5, s=10)\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title(f'{name}')\n",
    "    ax.legend(*scatter.legend_elements(), title='Класс')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Сравнение с истинными метками\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "scatter = ax.scatter(X_test_pca[:, 0], X_test_pca[:, 1],\n",
    "                     c=y_test, cmap='coolwarm', alpha=0.5, s=10)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Истинные метки (y_test)')\n",
    "ax.legend(*scatter.legend_elements(), title='Класс')\n",
    "plt.show()\n",
    "\n",
    "# Подсчет различий между моделями\n",
    "print(\"=\" * 50)\n",
    "print(\"Совпадение прогнозов между моделями:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"SGD vs Full GD:     {(predictions['SGD (custom)'] == predictions['Full GD (custom)']).mean():.4f}\")\n",
    "print(f\"SGD vs sklearn:     {(predictions['SGD (custom)'] == predictions['sklearn LogReg']).mean():.4f}\")\n",
    "print(f\"Full GD vs sklearn: {(predictions['Full GD (custom)'] == predictions['sklearn LogReg']).mean():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ВЫВОД:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "Графики практически не различаются. Все три модели формируют очень похожие области классификации в проекции PCA, а различия носят минимальный характер и сосредоточены вблизи границы между классами. Так, визуально границы решений у моделей отличаются: у SGD граница более размытая, у Full GD — наиболее четкая и стабильная, а у sklearn LogisticRegression — промежуточная, что связано с использованием L-BFGS и L2-регуляризации. При этом различия затрагивают лишь область вблизи границы классов и практически не влияют на итоговые метрики качества.\n",
    "\n",
    "Причины схожести:\n",
    "-Все три модели — линейные классификаторы.\n",
    "-Задача выпуклая, и при достаточном числе итераций GD и SGD сходятся к близкому минимуму.\n",
    "-Данные синтетические и хорошо структурированы, поэтому нет сложной нелинейной границы.\n",
    "-PCA — это 2D-проекция, которая может сглаживать небольшие различия, существующие в исходном пространстве.\n",
    "\n",
    "Небольшие различия могут быть вызваны из-за:\n",
    "-стохастичности SGD (обновления по одному объекту);\n",
    "-разных критериев остановки;\n",
    "-наличия L2-регуляризации в sklearn;\n",
    "-различия в оптимизаторе (L-BFGS vs GD/SGD).\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Часть 2. Обучение моделей на текстовых данных. (5 баллов)**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ### **Подготовка данных из реального мира.**\n",
    "\n",
    "Ещё одна прелесть простых моделей — возможность решать с ними неструктурированные (изначально не табличные) задачи. Давайте посмотрим на это в действии на примере текстов.\n",
    "\n",
    "\n",
    "Загрузите данные с конкурса  [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/data?select=train.csv) (вам нужна только обучающая выборка, файл `train.csv`). Задача состоит в определении постов, сообщающих о чрезвычайной ситуации. В рамках домашнего задания, этот набор данных будет отличным полем для тренировки в обработке признаков."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PATH = 'train.csv'\n",
    "data = pd.read_csv(PATH)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 10. Базовая предобработка (1.5 балла).**\n",
    "\n",
    "- Выведите на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их пустой строкой (0.2 балла)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Анализ пропусков\n",
    "print(\"Информация о пропусках в данных:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\nПроцент пропусков:\")\n",
    "print(data.isnull().sum() / len(data) * 100)\n",
    "\n",
    "# Заполнение пропусков пустой строкой\n",
    "data['keyword'] = data['keyword'].fillna('')\n",
    "data['location'] = data['location'].fillna('')\n",
    "data['text'] = data['text'].fillna('')\n",
    "\n",
    "print(\"\\nПосле заполнения пропусков:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Проанализируйте количество уникальных значений в столбцах, опустив `text`. Сделайте выводы. (0.5 балла)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Анализ уникальных значений (без столбца text)\n",
    "print(\"Количество уникальных значений в столбцах:\")\n",
    "for col in data.columns:\n",
    "    if col != 'text':\n",
    "        print(f\"{col}: {data[col].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ВЫВОДЫ:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. id: {} уникальных значений - это идентификаторы твитов\".format(data['id'].nunique()))\n",
    "print(\"2. keyword: {} уникальных значений - ключевые слова из твитов\".format(data['keyword'].nunique()))\n",
    "print(\"   (с учетом пустых строк после заполнения пропусков)\")\n",
    "print(\"3. location: {} уникальных значений - местоположения авторов\".format(data['location'].nunique()))\n",
    "print(\"   (очень много разных локаций, что может указывать на шум в данных)\")\n",
    "print(\"4. target: {} класса - бинарная классификация (0 - не ЧС, 1 - ЧС)\".format(data['target'].nunique()))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Проанализируйте соотношение классов в целевой переменной. Какое оно? Выберите метрику, с помощью которой будете оценивать модель.  (0.5 балла)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Анализ баланса классов\n",
    "print(\"Распределение классов:\")\n",
    "print(data['target'].value_counts())\n",
    "print(\"\\nПроцентное соотношение:\")\n",
    "print(data['target'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "data['target'].value_counts().plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Класс (0 - не ЧС, 1 - ЧС)')\n",
    "ax.set_ylabel('Количество')\n",
    "ax.set_title('Распределение классов в целевой переменной')\n",
    "ax.set_xticklabels(['Не ЧС (0)', 'ЧС (1)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ВЫВОД:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Соотношение классов примерно 57% : 43% (не ЧС : ЧС).\")\n",
    "print(\"Данные слегка несбалансированы, но не критично.\")\n",
    "print(\"\\nВыбранная метрика: ROC-AUC\")\n",
    "print(\"Причина: ROC-AUC хорошо работает при небольшом дисбалансе классов\")\n",
    "print(\"и оценивает способность модели различать классы по вероятностям.\")\n",
    "print(\"Также будем использовать accuracy для дополнительной оценки.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Объедините все три текстовых столбца в один для baseline (вам поможет конкатенация строк) (0.3 балла)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Объединение текстовых столбцов для baseline\n",
    "# Конкатенация keyword, location и text с пробелами\n",
    "data_new = data.copy()\n",
    "data_new['text'] = data['keyword'] + ' ' + data['location'] + ' ' + data['text']\n",
    "\n",
    "print(\"Пример объединенного текста:\")\n",
    "print(data_new['text'].head(3))\n",
    "print(\"\\nФорма данных:\", data_new.shape)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Наконец, поделите данные на тренировочную и тестовую выборки. (0.2 балла)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = data_new['text']\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Размер обучающей выборки:\", X_train.shape)\n",
    "print(\"Размер тестовой выборки:\", X_test.shape)\n",
    "print(\"Распределение классов в обучающей выборке:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 11. Базовые модели. (1 балл).**\n",
    "\n",
    "Данные, собираемые с сайтов, часто содержат мусор не информативный для моделей. Посмотрите, какого качества и насколько разнообразны данные здесь. Для этого:\n",
    "- Примените CountVectorizer из sklearn к сырым даным. Какого размера получилась матрица? (0.3 балла)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Применяем CountVectorizer к сырым данным\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Размер матрицы признаков (обучающая выборка):\", X_train_vec.shape)\n",
    "print(\"Размер матрицы признаков (тестовая выборка):\", X_test_vec.shape)\n",
    "print(\"\\nКоличество объектов:\", X_train_vec.shape[0])\n",
    "print(\"Количество признаков (размер словаря):\", X_train_vec.shape[1])\n",
    "print(\"\\nМатрица получилась очень разреженной с {} уникальными словами\".format(X_train_vec.shape[1]))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Обучите логистическую регрессию на полученном наборе. Модель возьмите из библиотеки. Какое качество по выбранной вами метрике у модели получилось на тестовых данных? (0.3 балла)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Обучаем логистическую регрессию с улучшенными параметрами\n",
    "# C=1.0 - добавляем регуляризацию для численной стабильности\n",
    "# solver='liblinear' - более устойчивый solver для разреженных данных\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42, C=1.0, solver='liblinear')\n",
    "\n",
    "start_time = time.time()\n",
    "lr.fit(X_train_vec, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Предсказания\n",
    "y_pred_lr = lr.predict(X_test_vec)\n",
    "y_proba_lr = lr.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_proba_lr)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Логистическая регрессия (baseline)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Время обучения: {train_time:.2f} секунд\")\n",
    "print(f\"Accuracy на тесте: {acc_lr:.4f}\")\n",
    "print(f\"ROC-AUC на тесте: {roc_auc_lr:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Визуализация ROC-кривой для логистической регрессии\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_lr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {roc_auc_lr:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Logistic Regression')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Обучите SVC на тех же данных с гиперпараметрами по умолчанию. Измерьте качество на тестовых данных и опишите результат. Проанализируйте качество и скорость обучения.(0.4 балла)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# Обучаем SVC с гиперпараметрами по умолчанию\n",
    "svc = SVC(random_state=42, probability=True)\n",
    "\n",
    "start_time = time.time()\n",
    "svc.fit(X_train_vec, y_train)\n",
    "train_time_svc = time.time() - start_time\n",
    "\n",
    "# Предсказания\n",
    "y_pred_svc = svc.predict(X_test_vec)\n",
    "y_proba_svc = svc.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "# Метрики\n",
    "acc_svc = accuracy_score(y_test, y_pred_svc)\n",
    "roc_auc_svc = roc_auc_score(y_test, y_proba_svc)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SVC (baseline)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Время обучения: {train_time_svc:.2f} секунд\")\n",
    "print(f\"Accuracy на тесте: {acc_svc:.4f}\")\n",
    "print(f\"ROC-AUC на тесте: {roc_auc_svc:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"АНАЛИЗ РЕЗУЛЬТАТОВ:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Логистическая регрессия:\")\n",
    "print(f\"  - Время обучения: {train_time:.2f} сек\")\n",
    "print(f\"  - ROC-AUC: {roc_auc_lr:.4f}\")\n",
    "print(f\"\\nSVC:\")\n",
    "print(f\"  - Время обучения: {train_time_svc:.2f} сек\")\n",
    "print(f\"  - ROC-AUC: {roc_auc_svc:.4f}\")\n",
    "print(f\"\\nВЫВОД:\")\n",
    "print(f\"SVC обучается значительно медленнее (в {train_time_svc/train_time:.1f} раз),\")\n",
    "print(f\"но показывает {'лучшее' if roc_auc_svc > roc_auc_lr else 'аналогичное'} качество.\")\n",
    "print(\"Для больших датасетов логистическая регрессия предпочтительнее\")\n",
    "print(\"из-за скорости обучения при сопоставимом качестве.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Задание 12. Улучшение базовых моделей за счет данных. (0.3 балла).**"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Подберите гиперпараметры CountVectorizer так, чтобы признаков было минимум в 4 раза меньше, чем объектов, а качество модели при этом изменилось не более чем на $\\pm 0.07$. Опишите подобранные гиперпараметры и на что они влияют.\n",
    "\n",
    "Обучайте и логистическую регрессию, и SVC."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Подбор гиперпараметров CountVectorizer\n",
    "# Цель: признаков минимум в 4 раза меньше объектов (5329 / 4 = 1332)\n",
    "# при этом качество должно измениться не более чем на ±0.07\n",
    "\n",
    "# Используем следующие гиперпараметры:\n",
    "# - max_features: ограничиваем количество признаков\n",
    "# - min_df: минимальная частота документов для слова\n",
    "# - max_df: максимальная частота документов (убираем очень частые слова)\n",
    "# - ngram_range: используем униграммы и биграммы\n",
    "\n",
    "vectorizer_improved = CountVectorizer(\n",
    "    max_features=1200,  # Ограничиваем количество признаков\n",
    "    min_df=2,           # Слово должно встречаться минимум в 2 документах\n",
    "    max_df=0.8,         # Убираем слова, встречающиеся более чем в 80% документов\n",
    "    ngram_range=(1, 2)  # Используем униграммы и биграммы\n",
    ")\n",
    "\n",
    "X_train_vec_improved = vectorizer_improved.fit_transform(X_train)\n",
    "X_test_vec_improved = vectorizer_improved.transform(X_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Улучшенный CountVectorizer\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Количество объектов: {X_train_vec_improved.shape[0]}\")\n",
    "print(f\"Количество признаков: {X_train_vec_improved.shape[1]}\")\n",
    "print(f\"Соотношение объекты/признаки: {X_train_vec_improved.shape[0] / X_train_vec_improved.shape[1]:.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nОписание подобранных гиперпараметров:\")\n",
    "print(\"1. max_features=1200 - ограничивает словарь 1200 наиболее частыми словами\")\n",
    "print(\"   Влияние: уменьшает размерность, убирает редкие/шумные признаки\")\n",
    "print(\"\\n2. min_df=2 - слово должно встретиться минимум в 2 документах\")\n",
    "print(\"   Влияние: фильтрует опечатки и очень редкие слова\")\n",
    "print(\"\\n3. max_df=0.8 - исключает слова, встречающиеся в >80% документов\")\n",
    "print(\"   Влияние: убирает стоп-слова (the, is, a, etc.)\")\n",
    "print(\"\\n4. ngram_range=(1,2) - использует униграммы и биграммы\")\n",
    "print(\"   Влияние: учитывает контекст слов (например, 'not good' vs 'good')\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Обучаем LogisticRegression на улучшенных признаках\n",
    "# Используем solver='liblinear' для численной стабильности\n",
    "lr_improved = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')\n",
    "lr_improved.fit(X_train_vec_improved, y_train)\n",
    "\n",
    "y_pred_lr_improved = lr_improved.predict(X_test_vec_improved)\n",
    "y_proba_lr_improved = lr_improved.predict_proba(X_test_vec_improved)[:, 1]\n",
    "\n",
    "acc_lr_improved = accuracy_score(y_test, y_pred_lr_improved)\n",
    "roc_auc_lr_improved = roc_auc_score(y_test, y_proba_lr_improved)\n",
    "\n",
    "# Обучаем SVC на улучшенных признаках\n",
    "svc_improved = SVC(random_state=42, probability=True)\n",
    "svc_improved.fit(X_train_vec_improved, y_train)\n",
    "\n",
    "y_pred_svc_improved = svc_improved.predict(X_test_vec_improved)\n",
    "y_proba_svc_improved = svc_improved.predict_proba(X_test_vec_improved)[:, 1]\n",
    "\n",
    "acc_svc_improved = accuracy_score(y_test, y_pred_svc_improved)\n",
    "roc_auc_svc_improved = roc_auc_score(y_test, y_proba_svc_improved)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"=\"*60)\n",
    "print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Модель':<30} {'Baseline ROC-AUC':<20} {'Improved ROC-AUC':<20} {'Изменение':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Logistic Regression':<30} {roc_auc_lr:<20.4f} {roc_auc_lr_improved:<20.4f} {roc_auc_lr_improved - roc_auc_lr:+.4f}\")\n",
    "print(f\"{'SVC':<30} {roc_auc_svc:<20.4f} {roc_auc_svc_improved:<20.4f} {roc_auc_svc_improved - roc_auc_svc:+.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Проверка условий задания\n",
    "change_lr = abs(roc_auc_lr_improved - roc_auc_lr)\n",
    "change_svc = abs(roc_auc_svc_improved - roc_auc_svc)\n",
    "\n",
    "print(f\"\\nУсловие 1: Признаков в 4+ раза меньше объектов\")\n",
    "print(f\"  {X_train_vec_improved.shape[0]} / {X_train_vec_improved.shape[1]} = {X_train_vec_improved.shape[0] / X_train_vec_improved.shape[1]:.2f} ✓\")\n",
    "print(f\"\\nУсловие 2: Качество изменилось не более чем на ±0.07\")\n",
    "print(f\"  LogReg: {change_lr:.4f} {'✓' if change_lr <= 0.07 else '✗'}\")\n",
    "print(f\"  SVC: {change_svc:.4f} {'✓' if change_svc <= 0.07 else '✗'}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 13. Улучшение базовых моделей за счет данных 2. (0.7 балла).**\n",
    "\n",
    "В первом пункте мы склеили все строки в одну. Но можно было бы поступить иначе — и получить категории из `'keyword', 'location'`. Протестируйте такой подход на обеих моделях и замерьте качество. Улучшает ли это результат?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# Вместо конкатенации, обрабатываем текст отдельно, а keyword и location как категории\n",
    "# Векторизуем только текст\n",
    "vectorizer_text = CountVectorizer(max_features=1200, min_df=2, max_df=0.8, ngram_range=(1, 2))\n",
    "\n",
    "# Подготовка данных\n",
    "X_train_text = data.loc[X_train.index, 'text'].fillna('')\n",
    "X_test_text = data.loc[X_test.index, 'text'].fillna('')\n",
    "\n",
    "X_train_text_vec = vectorizer_text.fit_transform(X_train_text)\n",
    "X_test_text_vec = vectorizer_text.transform(X_test_text)\n",
    "\n",
    "# Категориальные признаки: keyword и location\n",
    "X_train_keyword = data.loc[X_train.index, 'keyword'].fillna('').values.reshape(-1, 1)\n",
    "X_test_keyword = data.loc[X_test.index, 'keyword'].fillna('').values.reshape(-1, 1)\n",
    "\n",
    "X_train_location = data.loc[X_train.index, 'location'].fillna('').values.reshape(-1, 1)\n",
    "X_test_location = data.loc[X_test.index, 'location'].fillna('').values.reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding для категорий\n",
    "encoder_keyword = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "encoder_location = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "X_train_keyword_enc = encoder_keyword.fit_transform(X_train_keyword)\n",
    "X_test_keyword_enc = encoder_keyword.transform(X_test_keyword)\n",
    "\n",
    "X_train_location_enc = encoder_location.fit_transform(X_train_location)\n",
    "X_test_location_enc = encoder_location.transform(X_test_location)\n",
    "\n",
    "# Объединяем все признаки\n",
    "X_train_combined = hstack([X_train_text_vec, X_train_keyword_enc, X_train_location_enc])\n",
    "X_test_combined = hstack([X_test_text_vec, X_test_keyword_enc, X_test_location_enc])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Признаки с категориями\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Размерность текстовых признаков: {X_train_text_vec.shape[1]}\")\n",
    "print(f\"Размерность keyword признаков: {X_train_keyword_enc.shape[1]}\")\n",
    "print(f\"Размерность location признаков: {X_train_location_enc.shape[1]}\")\n",
    "print(f\"Итоговая размерность: {X_train_combined.shape[1]}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Обучаем модели на признаках с категориями (X_train_combined)\n",
    "print(\"Обучение моделей на признаках с категориями...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# LogisticRegression с категориями\n",
    "lr_categories = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')\n",
    "lr_categories.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred_lr_cat = lr_categories.predict(X_test_combined)\n",
    "y_proba_lr_cat = lr_categories.predict_proba(X_test_combined)[:, 1]\n",
    "\n",
    "acc_lr_cat = accuracy_score(y_test, y_pred_lr_cat)\n",
    "roc_auc_lr_cat = roc_auc_score(y_test, y_proba_lr_cat)\n",
    "\n",
    "# SVC с категориями\n",
    "svc_categories = SVC(random_state=42, probability=True)\n",
    "svc_categories.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred_svc_cat = svc_categories.predict(X_test_combined)\n",
    "y_proba_svc_cat = svc_categories.predict_proba(X_test_combined)[:, 1]\n",
    "\n",
    "acc_svc_cat = accuracy_score(y_test, y_pred_svc_cat)\n",
    "roc_auc_svc_cat = roc_auc_score(y_test, y_proba_svc_cat)\n",
    "\n",
    "# Сравнение с baseline (из задания 12 - улучшенный vectorizer)\n",
    "print(\"\\nСРАВНЕНИЕ ПОДХОДОВ:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Модель':<30} {'Конкатенация':<20} {'Категории':<20} {'Разница':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Logistic Regression':<30} {roc_auc_lr_improved:<20.4f} {roc_auc_lr_cat:<20.4f} {roc_auc_lr_cat - roc_auc_lr_improved:+.4f}\")\n",
    "print(f\"{'SVC':<30} {roc_auc_svc_improved:<20.4f} {roc_auc_svc_cat:<20.4f} {roc_auc_svc_cat - roc_auc_svc_improved:+.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ответ на вопрос задания\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ОТВЕТ НА ВОПРОС: Улучшает ли использование категорий результат?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if roc_auc_lr_cat > roc_auc_lr_improved and roc_auc_svc_cat > roc_auc_svc_improved:\n",
    "    print(\"ДА, использование категорий улучшает качество обеих моделей!\")\n",
    "    print(f\"LogReg: улучшение на {(roc_auc_lr_cat - roc_auc_lr_improved)*100:.2f}%\")\n",
    "    print(f\"SVC: улучшение на {(roc_auc_svc_cat - roc_auc_svc_improved)*100:.2f}%\")\n",
    "elif roc_auc_lr_cat < roc_auc_lr_improved or roc_auc_svc_cat < roc_auc_svc_improved:\n",
    "    print(\"НЕТ, использование категорий НЕ улучшает результат.\")\n",
    "    print(f\"LogReg: изменение {(roc_auc_lr_cat - roc_auc_lr_improved)*100:+.2f}%\")\n",
    "    print(f\"SVC: изменение {(roc_auc_svc_cat - roc_auc_svc_improved)*100:+.2f}%\")\n",
    "    print(\"\\nВОЗМОЖНЫЕ ПРИЧИНЫ:\")\n",
    "    print(\"- Location содержит много шума (2471 уникальных значений)\")\n",
    "    print(\"- Конкатенация текста уже включает информацию из keyword и location\")\n",
    "    print(\"- Модель переобучается на разреженных категориальных признаках\")\n",
    "else:\n",
    "    print(\"РЕЗУЛЬТАТЫ СМЕШАННЫЕ - одна модель улучшилась, другая ухудшилась\")\n",
    "\n",
    "print(f\"\\nИтоговая размерность с категориями: {X_train_combined.shape[1]} признаков\")\n",
    "print(f\"Размерность с конкатенацией: {X_train_vec_improved.shape[1]} признаков\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Задание 13. Улучшение базовых моделей путем подбора гиперпараметров. (1 балл).**\n",
    "- Попробуйте подбирать разные гиперпараметры для логистической регрессии. Опишите подбираемые гиперапарметры и ваши результаты (0.5 балла)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Подбор гиперпараметров для LogisticRegression\n",
    "# Основные гиперпараметры:\n",
    "# - C: обратная величина регуляризации (меньше C = сильнее регуляризация)\n",
    "# - penalty: тип регуляризации (l1, l2, elasticnet)\n",
    "# - solver: алгоритм оптимизации\n",
    "\n",
    "# Используем только liblinear для стабильности и избежания warnings\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],                    # Сила регуляризации\n",
    "    'penalty': ['l1', 'l2'],                   # Тип регуляризации\n",
    "    'solver': ['liblinear']                    # liblinear работает с l1 и l2, устойчив к численным проблемам\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Подбор гиперпараметров для LogisticRegression...\")\n",
    "lr_grid.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ПОДБОРА ГИПЕРПАРАМЕТРОВ - LogisticRegression\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Лучшие параметры: {lr_grid.best_params_}\")\n",
    "print(f\"Лучший ROC-AUC (CV): {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "# Тестируем на тестовой выборке\n",
    "y_proba_lr_tuned = lr_grid.best_estimator_.predict_proba(X_test_combined)[:, 1]\n",
    "roc_auc_lr_tuned = roc_auc_score(y_test, y_proba_lr_tuned)\n",
    "print(f\"ROC-AUC на тесте: {roc_auc_lr_tuned:.4f}\")\n",
    "print(f\"Улучшение по сравнению с baseline: {roc_auc_lr_tuned - roc_auc_lr:+.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nОПИСАНИЕ ГИПЕРПАРАМЕТРОВ:\")\n",
    "print(\"1. C - обратная сила регуляризации:\")\n",
    "print(\"   - Меньшие значения (0.1) = сильная регуляризация = проще модель\")\n",
    "print(\"   - Большие значения (100) = слабая регуляризация = сложнее модель\")\n",
    "print(\"\\n2. penalty - тип регуляризации:\")\n",
    "print(\"   - 'l2' (Ridge): штрафует квадрат весов, делает их маленькими\")\n",
    "print(\"   - 'l1' (Lasso): может обнулять веса, выполняет отбор признаков\")\n",
    "print(\"\\n3. solver - алгоритм оптимизации:\")\n",
    "print(\"   - 'liblinear': оптимален для малых/средних данных, работает с l1 и l2,\")\n",
    "print(\"     устойчив к численным проблемам с разреженными матрицами\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Подбор гиперпараметров для SVC\n",
    "# Основные гиперпараметры:\n",
    "# - C: параметр регуляризации\n",
    "# - kernel: тип ядра (linear, rbf, poly)\n",
    "# - gamma: коэффициент ядра для rbf, poly\n",
    "\n",
    "# Используем меньший grid для SVC, так как он обучается медленно\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],                    # Сила регуляризации\n",
    "    'kernel': ['linear', 'rbf'],          # Тип ядра\n",
    "    'gamma': ['scale', 'auto']            # Коэффициент ядра\n",
    "}\n",
    "\n",
    "svc_grid = GridSearchCV(\n",
    "    SVC(random_state=42, probability=True),\n",
    "    param_grid_svc,\n",
    "    cv=3,  # Меньше фолдов для ускорения\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Подбор гиперпараметров для SVC...\")\n",
    "print(\"(это может занять несколько минут...)\")\n",
    "svc_grid.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ПОДБОРА ГИПЕРПАРАМЕТРОВ - SVC\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Лучшие параметры: {svc_grid.best_params_}\")\n",
    "print(f\"Лучший ROC-AUC (CV): {svc_grid.best_score_:.4f}\")\n",
    "\n",
    "# Тестируем на тестовой выборке\n",
    "y_proba_svc_tuned = svc_grid.best_estimator_.predict_proba(X_test_combined)[:, 1]\n",
    "roc_auc_svc_tuned = roc_auc_score(y_test, y_proba_svc_tuned)\n",
    "print(f\"ROC-AUC на тесте: {roc_auc_svc_tuned:.4f}\")\n",
    "print(f\"Улучшение по сравнению с baseline: {roc_auc_svc_tuned - roc_auc_svc:+.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nОПИСАНИЕ ГИПЕРПАРАМЕТРОВ:\")\n",
    "print(\"1. C - параметр регуляризации:\")\n",
    "print(\"   - Меньшие значения (0.1) = широкая разделяющая полоса = проще модель\")\n",
    "print(\"   - Большие значения (10) = узкая разделяющая полоса = сложнее модель\")\n",
    "print(\"\\n2. kernel - тип ядра:\")\n",
    "print(\"   - 'linear': линейное разделение, быстрое обучение\")\n",
    "print(\"   - 'rbf': нелинейное разделение (радиальная базисная функция)\")\n",
    "print(\"\\n3. gamma - коэффициент ядра (для rbf):\")\n",
    "print(\"   - 'scale': автоматический расчет на основе данных (рекомендуется)\")\n",
    "print(\"   - 'auto': 1 / n_features\")\n",
    "print(\"   - Большие gamma = учитывается только ближайшее окружение точки\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**ОБЩИЕ ВЫВОДЫ ПО ПОДБОРУ ГИПЕРПАРАМЕТРОВ:**\n",
    "\n",
    "1. Подбор гиперпараметров позволяет значительно улучшить качество моделей\n",
    "2. LogisticRegression обучается быстрее и хорошо подходит для текстовых данных\n",
    "3. SVC может показывать лучшее качество, но требует больше времени на обучение\n",
    "4. Использование GridSearchCV с кросс-валидацией помогает избежать переобучения\n",
    "5. Важно балансировать между сложностью модели и обобщающей способностью через регуляризацию"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ваши выводы здесь."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Создаем функции для извлечения признаков\n",
    "def get_text(df):\n",
    "    \"\"\"Извлекает текстовый столбец\"\"\"\n",
    "    if isinstance(df, pd.Series):\n",
    "        return df\n",
    "    return df['text'] if 'text' in df.columns else df\n",
    "\n",
    "def get_keyword(df):\n",
    "    \"\"\"Извлекает keyword столбец\"\"\"\n",
    "    if isinstance(df, pd.Series):\n",
    "        return pd.DataFrame({'keyword': [''] * len(df)})\n",
    "    return df[['keyword']].fillna('')\n",
    "\n",
    "def get_location(df):\n",
    "    \"\"\"Извлекает location столбец\"\"\"\n",
    "    if isinstance(df, pd.Series):\n",
    "        return pd.DataFrame({'location': [''] * len(df)})\n",
    "    return df[['location']].fillna('')\n",
    "\n",
    "# Пайплайн для LogisticRegression\n",
    "pipeline_lr = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('selector', FunctionTransformer(lambda x: x if isinstance(x, pd.Series) else x['text'].fillna(''), validate=False)),\n",
    "            ('vectorizer', CountVectorizer(max_features=1200, min_df=2, max_df=0.8, ngram_range=(1, 2)))\n",
    "        ])),\n",
    "        ('keyword', Pipeline([\n",
    "            ('selector', FunctionTransformer(lambda x: x[['keyword']].fillna('') if isinstance(x, pd.DataFrame) else pd.DataFrame({'keyword': ['']*len(x)}), validate=False)),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "        ])),\n",
    "        ('location', Pipeline([\n",
    "            ('selector', FunctionTransformer(lambda x: x[['location']].fillna('') if isinstance(x, pd.DataFrame) else pd.DataFrame({'location': ['']*len(x)}), validate=False)),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Пайплайн для SVC\n",
    "pipeline_svc = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('selector', FunctionTransformer(lambda x: x if isinstance(x, pd.Series) else x['text'].fillna(''), validate=False)),\n",
    "            ('vectorizer', CountVectorizer(max_features=1200, min_df=2, max_df=0.8, ngram_range=(1, 2)))\n",
    "        ])),\n",
    "        ('keyword', Pipeline([\n",
    "            ('selector', FunctionTransformer(lambda x: x[['keyword']].fillna('') if isinstance(x, pd.DataFrame) else pd.DataFrame({'keyword': ['']*len(x)}), validate=False)),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "        ])),\n",
    "        ('location', Pipeline([\n",
    "            ('selector', FunctionTransformer(lambda x: x[['location']].fillna('') if isinstance(x, pd.DataFrame) else pd.DataFrame({'location': ['']*len(x)}), validate=False)),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', SVC(C=10, kernel='rbf', gamma='scale', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"СОЗДАНИЕ И ТЕСТИРОВАНИЕ ПАЙПЛАЙНОВ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Подготовка данных для пайплайнов (используем исходный DataFrame)\n",
    "X_train_df = data.loc[X_train.index, ['text', 'keyword', 'location']]\n",
    "X_test_df = data.loc[X_test.index, ['text', 'keyword', 'location']]\n",
    "\n",
    "# Обучение и тестирование пайплайна LogisticRegression\n",
    "print(\"\\nОбучение пайплайна LogisticRegression...\")\n",
    "pipeline_lr.fit(X_train_df, y_train)\n",
    "y_proba_pipeline_lr = pipeline_lr.predict_proba(X_test_df)[:, 1]\n",
    "roc_auc_pipeline_lr = roc_auc_score(y_test, y_proba_pipeline_lr)\n",
    "\n",
    "print(f\"ROC-AUC (LogisticRegression Pipeline): {roc_auc_pipeline_lr:.4f}\")\n",
    "\n",
    "# Обучение и тестирование пайплайна SVC\n",
    "print(\"\\nОбучение пайплайна SVC...\")\n",
    "pipeline_svc.fit(X_train_df, y_train)\n",
    "y_proba_pipeline_svc = pipeline_svc.predict_proba(X_test_df)[:, 1]\n",
    "roc_auc_pipeline_svc = roc_auc_score(y_test, y_proba_pipeline_svc)\n",
    "\n",
    "print(f\"ROC-AUC (SVC Pipeline): {roc_auc_pipeline_svc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СТРУКТУРА ПАЙПЛАЙНОВ:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nОба пайплайна включают:\")\n",
    "print(\"1. Feature extraction:\")\n",
    "print(\"   - Text: CountVectorizer с оптимизированными параметрами\")\n",
    "print(\"   - Keyword: OneHotEncoder для категориальных признаков\")\n",
    "print(\"   - Location: OneHotEncoder для категориальных признаков\")\n",
    "print(\"2. Feature union: объединение всех признаков\")\n",
    "print(\"3. Classifier: LogisticRegression или SVC с настроенными параметрами\")\n",
    "print(\"\\nПреимущества пайплайна:\")\n",
    "print(\"- Автоматическая предобработка новых данных\")\n",
    "print(\"- Предотвращение утечки данных между train и test\")\n",
    "print(\"- Удобство в продакшене\")\n",
    "print(\"- Простота в использовании с GridSearchCV\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Опишите общие мысли о работе. Это место для вашей рефлексии, не обязательное, но полезное.**  🐤"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "fxmJha91VB90"
   ],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
